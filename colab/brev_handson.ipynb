{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMS9Z4OtZYeSfA/IkED2HzU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NVIDIA/synthda/blob/main/colab/brev_handson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYb-4YZDjsJt"
      },
      "outputs": [],
      "source": [
        "# Note that in this demo, we are using PyRender NOT Blender due to constraints since this is run headlessly\n",
        "# If you found this useful, please cite our work!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and Setting up SynthDa repo (Optional if you have your own models you'd like to use instead )"
      ],
      "metadata": {
        "id": "Xw59CK1TdTSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a local directory for autosynthda project\n",
        "!mkdir -p ~/autosynthda/indiv\n",
        "\n",
        "# Clone the synthda repo into that directory\n",
        "!git clone https://github.com/NVIDIA/synthda ~/autosynthda/indiv\n"
      ],
      "metadata": {
        "id": "34MyUItNdhLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Requirements for each new runtime"
      ],
      "metadata": {
        "id": "cUG_w9f0SqeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory (Jupyter magic `%cd` is okay)\n",
        "%cd ~/autosynthda/indiv/components\n",
        "\n",
        "# List files (needs `!`)\n",
        "!ls\n",
        "\n",
        "\n",
        "!find ~/autosynthda/indiv/components -name requirements.txt\n"
      ],
      "metadata": {
        "id": "YzTMKDATdhEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ~/autosynthda/indiv/components/requirements.txt\n",
        "\n",
        "#in Brev sometimes there is only python3 so sync the 2 with a link\n",
        "!sudo ln -s /usr/bin/python3 /usr/bin/python\n"
      ],
      "metadata": {
        "id": "bRDVN1kxdhCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \\\n",
        "    numpy==1.23.5 \\\n",
        "    yacs \\\n",
        "    filterpy \\\n",
        "    smplx==0.1.28 \\\n",
        "    trimesh==3.9.0 \\\n",
        "    chumpy==0.70 \\\n",
        "    python-dotenv\n"
      ],
      "metadata": {
        "id": "_lYk5HrOdg_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall broken/conflicting versions\n",
        "!pip uninstall -y numpy matplotlib\n",
        "\n",
        "# Reinstall compatible versions\n",
        "!pip install numpy==1.24.4 matplotlib==3.7.2\n",
        "\n",
        "!pip install spacy\n"
      ],
      "metadata": {
        "id": "wrT8pM9M56qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hardcoded fix for chumpy for python 3.11\n",
        "\n",
        "import inspect\n",
        "\n",
        "# Monkey patch getargspec for chumpy compatibility with Python ≥3.11\n",
        "if not hasattr(inspect, 'getargspec'):\n",
        "    from collections import namedtuple\n",
        "\n",
        "    ArgSpec = namedtuple('ArgSpec', 'args varargs keywords defaults')\n",
        "\n",
        "    def getargspec(func):\n",
        "        sig = inspect.signature(func)\n",
        "        args = []\n",
        "        varargs = None\n",
        "        keywords = None\n",
        "        defaults = []\n",
        "\n",
        "        for name, param in sig.parameters.items():\n",
        "            if param.kind in (param.POSITIONAL_ONLY, param.POSITIONAL_OR_KEYWORD):\n",
        "                args.append(name)\n",
        "                if param.default is not param.empty:\n",
        "                    defaults.append(param.default)\n",
        "            elif param.kind == param.VAR_POSITIONAL:\n",
        "                varargs = name\n",
        "            elif param.kind == param.VAR_KEYWORD:\n",
        "                keywords = name\n",
        "\n",
        "        return ArgSpec(args, varargs, keywords, tuple(defaults) if defaults else None)\n",
        "\n",
        "    inspect.getargspec = getargspec\n"
      ],
      "metadata": {
        "id": "JBNPFS7tdod_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Install Repos [If done previously, then can skip this]"
      ],
      "metadata": {
        "id": "0pFGbWzAdyoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone required repositories into Brev local path\n",
        "!git clone https://github.com/Vegetebird/StridedTransformer-Pose3D.git ~/autosynthda/indiv/StridedTransformer-Pose3D\n",
        "!git clone https://github.com/EricGuo5513/text-to-motion.git ~/autosynthda/indiv/text-to-motion\n",
        "!git clone https://github.com/wangsen1312/joints2smpl.git ~/autosynthda/indiv/joints2smpl\n",
        "\n",
        "# (Optional) Clone SlowFast if needed\n",
        "# !git clone https://github.com/facebookresearch/SlowFast.git ~/autosynthda/indiv/SlowFast\n",
        "\n",
        "# Download Blender 3.0.0 into ~/autosynthda/indiv\n",
        "#!wget -P ~/autosynthda/indiv https://download.blender.org/release/Blender3.0/blender-3.0.0-linux-x64.tar.xz\n",
        "\n",
        "# Extract Blender in the same directory\n",
        "#!tar -xf ~/autosynthda/indiv/blender-3.0.0-linux-x64.tar.xz -C ~/autosynthda/indiv\n"
      ],
      "metadata": {
        "id": "zYso70lldoat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup of gdown, and setting up the needed smpl neutral file if you dont already have it\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure gdown is installed and ~/.local/bin is on PATH\n",
        "subprocess.run([\"pip\", \"install\", \"--user\", \"--quiet\", \"gdown\"], check=True)\n",
        "os.environ[\"PATH\"] += os.pathsep + os.path.expanduser(\"~/.local/bin\")\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "target_path = Path(\"~/autosynthda/indiv/joints2smpl/smpl_models/smpl\").expanduser()\n",
        "target_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download the SMPL_NEUTRAL.pkl file\n",
        "download_cmd = f\"gdown --id 1KTFG5IKNKXi6Ri0UZomKBnh1Ze8uuElH -O {target_path / 'SMPL_NEUTRAL.pkl'}\"\n",
        "subprocess.run(download_cmd, shell=True, check=True)\n",
        "\n",
        "# Verify download\n",
        "if (target_path / \"SMPL_NEUTRAL.pkl\").exists():\n",
        "    print(\"✅ SMPL_NEUTRAL.pkl successfully downloaded.\")\n",
        "else:\n",
        "    print(\"❌ Download failed.\")\n"
      ],
      "metadata": {
        "id": "iuWLUwMSQDfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PATH\"] += os.pathsep + os.path.expanduser(\"~/.local/bin\")\n",
        "\n",
        "\n",
        "# Change directory into the StridedTransformer repo\n",
        "os.chdir(os.path.expanduser('~/autosynthda/indiv/StridedTransformer-Pose3D'))\n",
        "\n",
        "# Install gdown if needed\n",
        "!pip install -q gdown\n",
        "\n",
        "# Make sure the pretrained checkpoint directory exists\n",
        "os.makedirs('checkpoint/pretrained', exist_ok=True)\n",
        "\n",
        "# Download the two refine/non-refine checkpoints if missing\n",
        "if not os.path.exists('checkpoint/pretrained/refine_4365.pth'):\n",
        "    !gdown https://drive.google.com/uc?id=1aDLu0SB9JnPYZOOzQsJMV9zEIHg2Uro7 \\\n",
        "           -O checkpoint/pretrained/refine_4365.pth\n",
        "\n",
        "if not os.path.exists('checkpoint/pretrained/no_refine_4365.pth'):\n",
        "    !gdown https://drive.google.com/uc?id=1l63AI9BsNovpfTAbfAkySo9X2MOWgYZH \\\n",
        "           -O checkpoint/pretrained/no_refine_4365.pth\n",
        "\n",
        "# Ensure the demo/lib/checkpoint directory exists\n",
        "os.makedirs('demo/lib/checkpoint', exist_ok=True)\n",
        "\n",
        "# Download YOLOv3 weights\n",
        "if not os.path.exists('demo/lib/checkpoint/yolov3.weights'):\n",
        "    !gdown https://drive.google.com/uc?id=1gWZl1VrlLZKBf0Pfkj4hKiFxe8sHP-1C \\\n",
        "           -O demo/lib/checkpoint/yolov3.weights\n",
        "\n",
        "# Download HRNet pose model\n",
        "if not os.path.exists('demo/lib/checkpoint/pose_hrnet_w48_384x288.pth'):\n",
        "    !gdown https://drive.google.com/uc?id=1CpyZiUIUlEjiql4rILwdBT4666S72Oq4 \\\n",
        "           -O demo/lib/checkpoint/pose_hrnet_w48_384x288.pth\n"
      ],
      "metadata": {
        "id": "6hKq3Q7Udg9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install unzip -y\n"
      ],
      "metadata": {
        "id": "V8o2MMq-Vp5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ensure gdown works by adding .local/bin to PATH\n",
        "os.environ[\"PATH\"] += os.pathsep + os.path.expanduser(\"~/.local/bin\")\n",
        "\n",
        "# Change to text-to-motion directory\n",
        "os.chdir(os.path.expanduser('~/autosynthda/indiv/text-to-motion'))\n",
        "\n",
        "# Make sure checkpoints1 directory exists\n",
        "os.makedirs('checkpoints1', exist_ok=True)\n",
        "\n",
        "# Install gdown silently\n",
        "!pip install -q gdown\n",
        "\n",
        "# Download and unzip first model\n",
        "if not os.path.exists('checkpoints1/model.zip'):\n",
        "    !gdown --id 12liZW5iyvoybXD8eOw4VanTgsMtynCuU -O checkpoints1/model.zip\n",
        "    !unzip -q checkpoints1/model.zip -d checkpoints1\n",
        "\n",
        "# Download and unzip second model\n",
        "if not os.path.exists('checkpoints1/model2.zip'):\n",
        "    !gdown --id 1IgrFCnxeg4olBtURUHimzS03ZI0df_6W -O checkpoints1/model2.zip\n",
        "    !unzip -q checkpoints1/model2.zip -d checkpoints1\n"
      ],
      "metadata": {
        "id": "EIqd-Q4ndg4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename and clean up folder structure in preparation for the next steps\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "ttm_dir = Path('~/autosynthda/indiv/text-to-motion').expanduser()\n",
        "checkpoints_path = ttm_dir / 'checkpoints'\n",
        "checkpoints1_path = ttm_dir / 'checkpoints1'\n",
        "\n",
        "# Step 1: Force remove whatever is at 'checkpoints'\n",
        "try:\n",
        "    if checkpoints_path.is_symlink() or checkpoints_path.is_file():\n",
        "        checkpoints_path.unlink()\n",
        "        print(\"🗑️ Removed file/symlink 'checkpoints'\")\n",
        "    elif checkpoints_path.is_dir():\n",
        "        shutil.rmtree(checkpoints_path)\n",
        "        print(\"🗑️ Removed directory 'checkpoints'\")\n",
        "    elif checkpoints_path.exists():\n",
        "        os.remove(checkpoints_path)\n",
        "        print(\"🗑️ Removed special file 'checkpoints'\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Could not clean 'checkpoints': {e}\")\n",
        "\n",
        "# Step 2: Rename 'checkpoints1' → 'checkpoints'\n",
        "try:\n",
        "    if checkpoints1_path.exists() and checkpoints1_path.is_dir():\n",
        "        checkpoints1_path.rename(checkpoints_path)\n",
        "        print(\"✅ Renamed 'checkpoints1' → 'checkpoints'\")\n",
        "    else:\n",
        "        print(\"❌ 'checkpoints1' does not exist or is not a directory.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Rename failed: {e}\")\n"
      ],
      "metadata": {
        "id": "6onFvMnBd9kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Each Component for Sanity Check"
      ],
      "metadata": {
        "id": "7J5mxVLsfCFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0–5: Full setup with rendering and SMPL-compatible stack\n",
        "!pip uninstall -y numpy\n",
        "\n",
        "# Install NumPy 1.24.4 (compatible with matplotlib, numba, trimesh, chumpy)\n",
        "!pip install numpy==1.24.4\n",
        "\n",
        "# Install PyTorch with CUDA 12.4 (adjust index if needed)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# Install all required packages\n",
        "!pip install \\\n",
        "    iopath \\\n",
        "    fvcore \\\n",
        "    pytorchvideo \\\n",
        "    tensorboard \\\n",
        "    setuptools \\\n",
        "    torchinfo \\\n",
        "    opencv-python-headless \\\n",
        "    seaborn \\\n",
        "    Pillow \\\n",
        "    scikit-learn \\\n",
        "    scikit-image \\\n",
        "    matplotlib==3.7.2 \\\n",
        "    scipy==1.10.1 \\\n",
        "    numba \\\n",
        "    trimesh==3.23.5 \\\n",
        "    spacy \\\n",
        "    pyrender \\\n",
        "    imageio[ffmpeg] \\\n",
        "    pyglet \\\n",
        "    av \\\n",
        "    python-dotenv\n",
        "\n",
        "# Download spaCy English model\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "\n",
        "# Install ffmpeg system-wide (needed for .mp4 export from matplotlib/animation)\n",
        "!sudo apt update && sudo apt install -y ffmpeg\n"
      ],
      "metadata": {
        "id": "5dnJ-9nOXked"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AutoPatch for numpy version for text to motion\n",
        "# Automatically patch old uses of `np.float` -> `float` in your codebase\n",
        "import os\n",
        "\n",
        "target_dir = \"/home/ubuntu/autosynthda/indiv/text-to-motion\"\n",
        "\n",
        "for root, _, files in os.walk(target_dir):\n",
        "    for fname in files:\n",
        "        if fname.endswith(\".py\"):\n",
        "            fpath = os.path.join(root, fname)\n",
        "            with open(fpath, 'r') as file:\n",
        "                content = file.read()\n",
        "            patched = content.replace('np.float', 'float')  # or 'np.float64'\n",
        "            if content != patched:\n",
        "                with open(fpath, 'w') as file:\n",
        "                    file.write(patched)\n",
        "                print(f\"✔️ Patched {fpath}\")\n"
      ],
      "metadata": {
        "id": "e8Gwtkt9f_3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if below cell fails, even after restarting kernel then do this! and restart kernel again\n",
        "#!pip install --force-reinstall opencv-python-headless"
      ],
      "metadata": {
        "id": "IsS6vLGtX063"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm installation, BUT RESTART KERNEL FIRST!\n",
        "import cv2\n",
        "print(f\"✅ OpenCV version: {cv2.__version__}\")\n"
      ],
      "metadata": {
        "id": "AGAFywhDVz7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for the version of torch and whether cuda is used\n",
        "import torch\n",
        "print(\"Torch file:\", torch.__file__)\n",
        "print(\"CUDA attr exists:\", hasattr(torch, \"cuda\"))\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA version:\", torch.version.cuda)\n",
        "print(\"Device count:\", torch.cuda.device_count())"
      ],
      "metadata": {
        "id": "A0plBGPtXCc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define environment variable block\n",
        "env_vars = \"\"\"\\\n",
        "STRIDED_TRANSFORMER_PATH=~/autosynthda/indiv/StridedTransformer-Pose3D\n",
        "TEXT_TO_MOTION_PATH=~/autosynthda/indiv/text-to-motion\n",
        "JOINTS2SMPL_PATH=~/autosynthda/indiv/joints2smpl\n",
        "SLOWFAST_PATH=~/autosynthda/indiv/SlowFast\n",
        "BLENDER_BIN=~/autosynthda/indiv/blender-3.0.0-linux-x64/blender\n",
        "BLENDER_ROOT=~/autosynthda/indiv/blender-3.0.0-linux-x64\n",
        "BLENDER_PATH=~/autosynthda/indiv/blender-3.0.0-linux-x64/blender\n",
        "\"\"\"\n",
        "\n",
        "# Ensure parent directory exists\n",
        "env_path = os.path.expanduser('~/autosynthda/indiv/synthda/components/.env')\n",
        "os.makedirs(os.path.dirname(env_path), exist_ok=True)\n",
        "\n",
        "# Write to .env file\n",
        "with open(env_path, \"w\") as f:\n",
        "    f.write(env_vars.strip())\n",
        "\n",
        "print(f\"✅ .env written to {env_path}\")\n"
      ],
      "metadata": {
        "id": "0Od8Ajp5doXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load .env file with all path variables\n",
        "load_dotenv(os.path.expanduser('~/autosynthda/indiv/synthda/components/.env'))\n",
        "\n",
        "# Make sure .local/bin is in PATH in case wget/gdown were installed via pip\n",
        "os.environ[\"PATH\"] += os.pathsep + os.path.expanduser(\"~/.local/bin\")\n",
        "\n",
        "# Overwrite joints2smpl/fit_seq.py with modified version from GitHub\n",
        "!wget -O ~/autosynthda/indiv/joints2smpl/fit_seq.py \\\n",
        "  https://raw.githubusercontent.com/NVIDIA/synthda/main/colab/synthda_mods/fit_seq.py\n",
        "\n",
        "# Overwrite text-to-motion/utils/plot_script.py with modified version from GitHub\n",
        "!wget -O ~/autosynthda/indiv/text-to-motion/utils/plot_script.py \\\n",
        "  https://raw.githubusercontent.com/NVIDIA/synthda/main/colab/synthda_mods/plot_script.py\n"
      ],
      "metadata": {
        "id": "20ADxtPifB2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restart kernel again before running this\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "CBtKIjrOfKac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test that your strided transformer is working\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Navigate to the StridedTransformer repo\n",
        "strided_path = Path('~/autosynthda/indiv/StridedTransformer-Pose3D').expanduser()\n",
        "os.chdir(strided_path)\n",
        "\n",
        "# Run the visualization script\n",
        "!python3 demo/vis.py --video sample_video.mp4\n",
        "\n"
      ],
      "metadata": {
        "id": "unElOjv_d9hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out text to motion\n",
        "import os\n",
        "\n",
        "# Switch to the text-to-motion folder\n",
        "os.chdir(os.path.expanduser('~/autosynthda/indiv/text-to-motion'))\n",
        "\n",
        "# Run the motion generation script\n",
        "!python gen_motion_script.py \\\n",
        "    --name Comp_v6_KLD01 \\\n",
        "    --text_file input.txt \\\n",
        "    --repeat_time 1\n"
      ],
      "metadata": {
        "id": "Y4GvZ3B3fHYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-patch the file to fix deprecated np.bool\n",
        "file_path = os.path.expanduser(\"~/.local/lib/python3.10/site-packages/trimesh/voxel/runlength.py\")\n",
        "with open(file_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    for line in lines:\n",
        "        f.write(line.replace(\"dtype=np.bool\", \"dtype=bool\"))\n",
        "\n",
        "# install missing dependency where needed\n",
        "!pip install h5py\n"
      ],
      "metadata": {
        "id": "jFf3Xlq67nkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch chumpy to fix removed np.bool/np.int/np.object/etc.\n",
        "import pathlib\n",
        "\n",
        "chumpy_init = pathlib.Path.home() / \".local/lib/python3.10/site-packages/chumpy/__init__.py\"\n",
        "\n",
        "if chumpy_init.exists():\n",
        "    with open(chumpy_init, \"r\") as file:\n",
        "        content = file.read()\n",
        "    patched = content.replace(\n",
        "        \"from numpy import bool, int, float, complex, object, unicode, str, nan, inf\",\n",
        "        \"from numpy import nan, inf; bool=bool; int=int; float=float; complex=complex; object=object; str=str\"\n",
        "    )\n",
        "    with open(chumpy_init, \"w\") as file:\n",
        "        file.write(patched)\n",
        "    print(\"✅ Patched chumpy for NumPy >=1.24 compatibility.\")\n",
        "else:\n",
        "    print(\"❌ chumpy/__init__.py not found. Check your install path.\")\n"
      ],
      "metadata": {
        "id": "Kxxm6e6ShXBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes very very long fyi\n",
        "import os\n",
        "import importlib\n",
        "import smplx\n",
        "\n",
        "# Reload smplx in case of updates\n",
        "importlib.reload(smplx)\n",
        "\n",
        "# Switch to joints2smpl folder\n",
        "os.chdir(os.path.expanduser('~/autosynthda/indiv/joints2smpl'))\n",
        "\n",
        "# List the contents of the SMPL model directory\n",
        "!ls -lh ~/autosynthda/indiv/joints2smpl/smpl_models/smpl/\n",
        "\n",
        "# Run the SMPL fitting script on test_motion2.npy\n",
        "!python3 fit_seq.py --files test_motion2.npy\n"
      ],
      "metadata": {
        "id": "BIWjVjGEjJLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Source folder: joints2smpl/demo/demo_results/test_motion2\n",
        "src = os.path.expanduser('~/autosynthda/indiv/joints2smpl/demo/demo_results/test_motion2')\n",
        "\n",
        "# Destination folder: synthda/components/renders/test_motion2\n",
        "dst = os.path.expanduser('~/autosynthda/indiv/synthda/components/renders/test_motion2')\n",
        "\n",
        "# Ensure the parent directory exists\n",
        "os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "\n",
        "# Remove destination if it already exists\n",
        "if os.path.exists(dst):\n",
        "    shutil.rmtree(dst)\n",
        "\n",
        "# Copy the entire folder\n",
        "shutil.copytree(src, dst)\n",
        "print(\"✅ Folder copied to expected Blender input location.\")\n",
        "\n",
        "# Verify\n",
        "print(\"Exists:\", os.path.exists(dst))\n",
        "print(\"Contents:\", os.listdir(dst) if os.path.exists(dst) else \"Path does not exist.\")\n"
      ],
      "metadata": {
        "id": "S-TBepGafHUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternative Method for Simple and Quick rendering without OpenGL"
      ],
      "metadata": {
        "id": "-nyZoZUiTZn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trimesh imageio --quiet\n"
      ],
      "metadata": {
        "id": "cjVh66r4TZZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_about_axis(verts, axis='z', deg=90, center=None):\n",
        "    import numpy as np\n",
        "    if center is None:\n",
        "        center = verts.mean(axis=0)\n",
        "    theta = np.deg2rad(deg)\n",
        "    c, s = np.cos(theta), np.sin(theta)\n",
        "    Rx = np.array([[1, 0, 0],\n",
        "                   [0, c,-s],\n",
        "                   [0, s, c]])\n",
        "    Ry = np.array([[ c, 0, s],\n",
        "                   [ 0, 1, 0],\n",
        "                   [-s, 0, c]])\n",
        "    Rz = np.array([[c,-s, 0],\n",
        "                   [s, c, 0],\n",
        "                   [0, 0, 1]])\n",
        "    R = {'x': Rx, 'y': Ry, 'z': Rz}[axis.lower()]\n",
        "    return (verts - center) @ R.T + center\n",
        "\n",
        "# choose one then rerun\n",
        "ROT_AXIS = 'x'   # try 'x' first; if wrong, try 'y'\n",
        "ROT_DEG  = 90    # use -90 if it flips the other way\n"
      ],
      "metadata": {
        "id": "x181dNxlaAZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, imageio, numpy as np, trimesh, matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from IPython.display import HTML, display\n",
        "from base64 import b64encode\n",
        "\n",
        "frames_dir = os.path.expanduser('~/autosynthda/indiv/synthda/components/renders/test_motion2')\n",
        "\n",
        "def numeric_key(name):\n",
        "    m = re.match(r\"(\\d+)\", os.path.splitext(name)[0])\n",
        "    return int(m.group(1)) if m else 0\n",
        "\n",
        "ply_files = sorted([f for f in os.listdir(frames_dir) if f.lower().endswith('.ply')], key=numeric_key)\n",
        "assert ply_files, \"No .ply files found.\"\n",
        "\n",
        "# --- rotation helper (we'll rotate verts once to keep them upright) ---\n",
        "def rotate_about_axis(verts, axis='z', deg=0, center=None):\n",
        "    if center is None: center = verts.mean(axis=0)\n",
        "    t = np.deg2rad(deg); c, s = np.cos(t), np.sin(t)\n",
        "    Rx = np.array([[1,0,0],[0,c,-s],[0,s,c]])\n",
        "    Ry = np.array([[c,0,s],[0,1,0],[-s,0,c]])\n",
        "    Rz = np.array([[c,-s,0],[s,c,0],[0,0,1]])\n",
        "    R  = {'x':Rx,'y':Ry,'z':Rz}[axis.lower()]\n",
        "    return (verts - center) @ R.T + center\n",
        "\n",
        "# --- load 1st frame to set orientation + fixed bounds ---\n",
        "mesh0 = trimesh.load(os.path.join(frames_dir, ply_files[0]), process=False)\n",
        "if isinstance(mesh0, trimesh.Scene):\n",
        "    mesh0 = next(iter(mesh0.geometry.values()))\n",
        "v0, f0 = mesh0.vertices.copy(), mesh0.faces\n",
        "\n",
        "# << use whatever made your model upright earlier >>\n",
        "# e.g., rotate 90° about X (change axis/deg to what worked for you)\n",
        "v0 = rotate_about_axis(v0, axis='x', deg=90)\n",
        "\n",
        "center_ref = v0.mean(axis=0)\n",
        "extent0 = (v0.max(0) - v0.min(0)).max()\n",
        "pad = 0.05 * extent0\n",
        "fixed_lims = np.array([center_ref - (extent0/2 + pad), center_ref + (extent0/2 + pad)]).T  # x,y,z bounds\n",
        "\n",
        "def set_fixed_bounds(ax, lims):\n",
        "    ax.set_xlim(lims[0]); ax.set_ylim(lims[1]); ax.set_zlim(lims[2])\n",
        "\n",
        "# --- views you want (3 others) ---\n",
        "VIEWS = [\n",
        "    (\"front\",       15,  30),   # your current-ish view (optional)\n",
        "    (\"front_left\",  15, 120),\n",
        "    (\"front_right\", 15, -60),\n",
        "    (\"top_45\",      60,  30),\n",
        "]\n",
        "\n",
        "def render_view(elev, azim, out_path):\n",
        "    writer = imageio.get_writer(out_path, fps=30, quality=8)\n",
        "    for fname in ply_files:\n",
        "        m = trimesh.load(os.path.join(frames_dir, fname), process=False)\n",
        "        if isinstance(m, trimesh.Scene):\n",
        "            m = next(iter(m.geometry.values()))\n",
        "        verts = m.vertices\n",
        "        faces = m.faces\n",
        "\n",
        "        # keep orientation upright & centered relative to first frame\n",
        "        verts = rotate_about_axis(verts, axis='x', deg=90)\n",
        "        verts = verts + (center_ref - verts.mean(axis=0))\n",
        "\n",
        "        # draw one frame\n",
        "        fig = plt.figure(figsize=(5,5), dpi=144)\n",
        "        canvas = FigureCanvas(fig)\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        tri = Poly3DCollection(verts[faces], linewidths=0.05, alpha=1.0)\n",
        "        tri.set_edgecolor([0,0,0,0.1]); tri.set_facecolor([0.7,0.7,0.8,1.0])\n",
        "        ax.add_collection3d(tri)\n",
        "        set_fixed_bounds(ax, fixed_lims)\n",
        "        ax.axis(\"off\")\n",
        "        ax.view_init(elev=elev, azim=azim)\n",
        "\n",
        "        canvas.draw()\n",
        "        w, h = canvas.get_width_height()\n",
        "        img = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8).reshape(h, w, 3)\n",
        "        writer.append_data(img)\n",
        "        plt.close(fig)\n",
        "    writer.close()\n",
        "\n",
        "# Render all desired views\n",
        "out_files = []\n",
        "for name, elev, azim in VIEWS[1:]:  # skip first if you already have it; or use VIEWS to render all 4\n",
        "    out_path = os.path.join(frames_dir, f\"animation_{name}.mp4\")\n",
        "    render_view(elev, azim, out_path)\n",
        "    out_files.append(out_path)\n",
        "\n",
        "# Display inline\n",
        "for path in out_files:\n",
        "    mp4 = open(path, 'rb').read()\n",
        "    display(HTML(f\"<p><b>{os.path.basename(path)}</b></p>\"\n",
        "                 f\"<video width='720' controls>\"\n",
        "                 f\"<source src='data:video/mp4;base64,{b64encode(mp4).decode()}' type='video/mp4'>\"\n",
        "                 f\"</video>\"))\n"
      ],
      "metadata": {
        "id": "6JBpoDDATeCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this Brev Instance / Colab Instance, we do not use Blender as it may be too intensive. For Blender we would recc the local version of SynthDa. For strictly demo purposes we are using PyRender, but the quality will not be the same as Blender"
      ],
      "metadata": {
        "id": "aP8665QSkVZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/content/blender-3.0.0-linux-x64/blender -b -P /content/synthda/components/animation_pose.py -- --name <folder_with_ply_files>\n",
        "\n",
        "# may not work on on Colab easily as Blender is intensive + running blender headlessly on Colab has some challenges.\n",
        "# However you will be able to download the .fbx as well to view the animation locally.\n",
        "# For Colab, the suggested alternative is to use pyrender instead, which we use in the demo function created for BREV below!\n",
        "\n"
      ],
      "metadata": {
        "id": "ItzYyK-Qd9bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Your Own Demo Data [Trying out Real-Mix from SynthDa]"
      ],
      "metadata": {
        "id": "ipIi5J3oUpEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#impt!! restart the kernel before AND after this cell is run\n",
        "\n",
        "# Step 0: Completely remove local site-packages for numpy, scipy, trimesh, pyrender\n",
        "!rm -rf ~/.local/lib/python3.10/site-packages/numpy*\n",
        "!rm -rf ~/.local/lib/python3.10/site-packages/scipy*\n",
        "!rm -rf ~/.local/lib/python3.10/site-packages/trimesh*\n",
        "!rm -rf ~/.local/lib/python3.10/site-packages/pyrender*\n",
        "!rm -rf ~/.cache/pip  # Optional: Clears pip cache\n",
        "\n",
        "# Step 1: Install stable numpy first\n",
        "!pip install numpy==1.24.4\n",
        "\n",
        "# Step 2: Reinstall compiled deps against this version\n",
        "!pip install \\\n",
        "    scipy==1.10.1 \\\n",
        "    matplotlib==3.7.2 \\\n",
        "    trimesh==3.23.5 \\\n",
        "    pyrender==0.1.45 \\\n",
        "    imageio[ffmpeg] \\\n",
        "    pyglet \\\n",
        "    av\n"
      ],
      "metadata": {
        "id": "QvnYoc2xVz0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyrender\n",
        "import os\n",
        "\n",
        "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
        "# This checks if EGL platform is available by verifying if the environment is headless\n",
        "if os.environ.get(\"PYOPENGL_PLATFORM\") == \"egl\":\n",
        "    print(\"EGL is enabled via PYOPENGL_PLATFORM\")\n",
        "else:\n",
        "    print(\"EGL is not enabled or PYOPENGL_PLATFORM not set\")\n"
      ],
      "metadata": {
        "id": "JJXXI2malh4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.interpolate import interp1d\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add synthda components path to sys.path (Brev local path)\n",
        "components_path = os.path.expanduser(\"~/autosynthda/indiv/components\")\n",
        "sys.path.append(components_path)\n",
        "\n",
        "from optimisation.optimisation_utils import map_h36m_to_smpl, upsample_pose_data, compute_P_opt\n",
        "\n",
        "# used when both sources are real tracked motion data\n",
        "def main_real_real(real_path_npz_1, real_path_npz_2, folder_path):\n",
        "    folder_path = Path(folder_path)\n",
        "    folder_path_variations = folder_path / \"all_variations\"\n",
        "    folder_path_variations.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Output paths\n",
        "    real_data_1_path = folder_path / 'output_keypoints_3d_real1.npy'\n",
        "    real_data_2_path = folder_path / 'output_keypoints_3d_real2.npy'\n",
        "\n",
        "    print(real_data_1_path)\n",
        "    print(real_data_2_path)\n",
        "\n",
        "    # Map .npz to SMPL-22 .npy\n",
        "    real_data_1 = map_h36m_to_smpl(real_path_npz_1)\n",
        "    np.save(real_data_1_path, real_data_1)\n",
        "\n",
        "    real_data_2 = map_h36m_to_smpl(real_path_npz_2)\n",
        "    np.save(real_data_2_path, real_data_2)\n",
        "\n",
        "    # Load data to compare frame counts\n",
        "    P_r = np.load(real_data_1_path)\n",
        "    P_s = np.load(real_data_2_path)\n",
        "\n",
        "    # Determine which array is shorter\n",
        "    if P_r.shape[0] > P_s.shape[0]:\n",
        "        smaller_array = real_data_2_path\n",
        "        bigger_array = real_data_1_path\n",
        "        max_frames = P_r.shape[0]\n",
        "    else:\n",
        "        smaller_array = real_data_1_path\n",
        "        bigger_array = real_data_2_path\n",
        "        max_frames = P_s.shape[0]\n",
        "\n",
        "    # Upsample smaller array\n",
        "    pose_data_upsampled = upsample_pose_data(str(smaller_array), target_frames=max_frames)\n",
        "    extended_new_path = smaller_array.with_stem(smaller_array.stem + \"_extended\")\n",
        "    np.save(extended_new_path, pose_data_upsampled)\n",
        "    print(\"Upsampled shape:\", pose_data_upsampled.shape)\n",
        "\n",
        "    # Generate interpolated optimised variants\n",
        "    weight_pairs = [(0.1, 0.9), (0.2, 0.8), (0.3, 0.7), (0.4, 0.6),\n",
        "                    (0.5, 0.5), (0.6, 0.4), (0.7, 0.3), (0.8, 0.2), (0.9, 0.1)]\n",
        "\n",
        "    # Decide which file is the \"fixed\" longer one\n",
        "    if bigger_array == real_data_1_path:\n",
        "        fixed = real_data_1_path\n",
        "        variable = extended_new_path\n",
        "    else:\n",
        "        fixed = real_data_2_path\n",
        "        variable = extended_new_path\n",
        "\n",
        "    # Compute and save interpolations\n",
        "    for w_A, w_B in weight_pairs:\n",
        "        P_opt = compute_P_opt(str(fixed), str(variable), alpha=0.5, w_A=w_A, w_B=w_B)\n",
        "        np.save(folder_path_variations / f\"_euclidean_distances_wA{w_A}_wB{w_B}.npy\", P_opt)\n"
      ],
      "metadata": {
        "id": "Q-7XP5RnUx2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need to make sure the EGL is functional for Brev\n",
        "!sudo apt update\n",
        "!sudo apt install -y libegl1 libegl-dev libglvnd-dev libgles2\n",
        "!ldconfig -p | grep EGL\n",
        "# RESTART KERNEL AFTER THIS\n"
      ],
      "metadata": {
        "id": "CrT4P0JP5ncH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the permissions to your account / session\n",
        "!sudo usermod -aG video $USER\n",
        "# RESTART KERNEL"
      ],
      "metadata": {
        "id": "Nm0f9vwo5uZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# More admin matters, but run this too after the previous restart\n",
        "!newgrp video"
      ],
      "metadata": {
        "id": "z2saWd9C51aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo usermod -aG render $(whoami)\n"
      ],
      "metadata": {
        "id": "k4Y9OBtG-3bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo reboot\n"
      ],
      "metadata": {
        "id": "ktNeY13j-5r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.access('/dev/dri/renderD128', os.R_OK | os.W_OK))\n"
      ],
      "metadata": {
        "id": "9xTBGlNO-7OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import math\n",
        "import trimesh\n",
        "import pyrender\n",
        "from PIL import Image\n",
        "\n",
        "# Try EGL platform for headless rendering on GPU-enabled Brev VM\n",
        "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
        "\n",
        "# If EGL fails, try:\n",
        "# os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"\n",
        "\n",
        "# ---- Set your local paths on Brev (modify where needed) ----\n",
        "ply_dir = Path(\"~/autosynthda/indiv/components/renders/test_video_3_test_video_1_euclidean_distances_wA0.5_wB0.5\").expanduser()\n",
        "out_dir = Path(\"~/autosynthda/indiv/components/renders/testpng_video3_gen_frames\").expanduser()\n",
        "# --------------------------------------\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Build a single scene with camera and light\n",
        "scene = pyrender.Scene()\n",
        "camera = pyrender.PerspectiveCamera(yfov=math.radians(50.0))\n",
        "light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
        "scene.add(camera, pose=trimesh.transformations.translation_matrix([0, 0, 2]))\n",
        "scene.add(light,  pose=trimesh.transformations.translation_matrix([0, 0, 2]))\n",
        "\n",
        "# Initialize offscreen renderer\n",
        "r = pyrender.OffscreenRenderer(\n",
        "    viewport_width=1920,\n",
        "    viewport_height=1080,\n",
        "    point_size=1.0\n",
        ")\n",
        "\n",
        "# Load all .ply mesh files\n",
        "files = sorted(ply_dir.glob(\"*.ply\"))\n",
        "\n",
        "# Render each mesh as a frame\n",
        "for i, ply in enumerate(files):\n",
        "    mesh = trimesh.load_mesh(ply)\n",
        "    # If models need rotation (e.g., upright correction), uncomment below:\n",
        "    # mesh.apply_transform(trimesh.transformations.rotation_matrix(math.radians(90), [1, 0, 0]))\n",
        "\n",
        "    m = pyrender.Mesh.from_trimesh(mesh, smooth=False)\n",
        "\n",
        "    # Remove previous mesh nodes\n",
        "    for node in list(scene.mesh_nodes):\n",
        "        scene.remove_node(node)\n",
        "    scene.add(m)\n",
        "\n",
        "    # Render and save frame\n",
        "    color, _ = r.render(scene)\n",
        "    Image.fromarray(color).save(out_dir / f\"frame_{i:04d}.png\")\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(f\"Rendered {i+1}/{len(files)} frames\")\n",
        "\n",
        "# Cleanup renderer\n",
        "r.delete()\n",
        "print(\"✅ All frames saved in\", out_dir)\n"
      ],
      "metadata": {
        "id": "hiNriM4CU8s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import random\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from itertools import combinations\n",
        "from dotenv import dotenv_values\n",
        "\n",
        "import math\n",
        "import trimesh\n",
        "import pyrender\n",
        "from PIL import Image\n",
        "\n",
        "# ─── Config ────────────────────────────────────────────────────────────────────\n",
        "env_path = Path(\"~/autosynthda/indiv/synthda/components/.env\").expanduser()\n",
        "env = dotenv_values(env_path)\n",
        "\n",
        "# No more KeyError here\n",
        "STRIDED     = Path(env[\"STRIDED_TRANSFORMER_PATH\"]).expanduser()\n",
        "TEXT2M      = Path(env[\"TEXT_TO_MOTION_PATH\"]).expanduser()\n",
        "JOINTS2SMPL = Path(env[\"JOINTS2SMPL_PATH\"]).expanduser()\n",
        "COMP_ROOT   = Path(\"~/autosynthda/indiv/synthda/components\").expanduser()\n",
        "ANIM_REND   = COMP_ROOT / \"renders\"\n",
        "\n",
        "from optimisation.optimisation_utils import map_h36m_to_smpl, upsample_pose_data, compute_P_opt\n",
        "\n",
        "# ─── Helper: headless PLY→PNG via pyrender ──────────────────────────────────────\n",
        "def render_ply_sequence(ply_folder: Path, png_out: Path,\n",
        "                        width=1920, height=1080, fps=27):\n",
        "    os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
        "    png_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    scene = pyrender.Scene()\n",
        "    cam = pyrender.PerspectiveCamera(yfov=math.radians(50.0))\n",
        "    light = pyrender.DirectionalLight(color=[1.0, 1.0, 1.0], intensity=2.0)\n",
        "    scene.add(cam, pose=trimesh.transformations.translation_matrix([0, 0, 2]))\n",
        "    scene.add(light, pose=trimesh.transformations.translation_matrix([0, 0, 2]))\n",
        "\n",
        "    r = pyrender.OffscreenRenderer(viewport_width=width,\n",
        "                                   viewport_height=height,\n",
        "                                   point_size=1.0)\n",
        "\n",
        "    ply_files = sorted(ply_folder.glob(\"*.ply\"))\n",
        "    for idx, ply in enumerate(ply_files):\n",
        "        mesh = trimesh.load_mesh(str(ply))\n",
        "        # Uncomment if upright correction is needed:\n",
        "        # mesh.apply_transform(trimesh.transformations.rotation_matrix(math.radians(90), [1, 0, 0]))\n",
        "\n",
        "        m = pyrender.Mesh.from_trimesh(mesh, smooth=False)\n",
        "        for node in list(scene.mesh_nodes):\n",
        "            scene.remove_node(node)\n",
        "        scene.add(m)\n",
        "\n",
        "        color, _ = r.render(scene)\n",
        "        Image.fromarray(color).save(png_out / f\"frame_{idx:04d}.png\")\n",
        "\n",
        "    r.delete()\n",
        "\n",
        "# ─── Main pipeline ────────────────────────────────────────────────────────────\n",
        "def both_real_main(*, weight_A, input_dir, output_dir, num_pairs):\n",
        "    random.seed(42)\n",
        "    video_dir = Path(input_dir).expanduser()\n",
        "    out_root = Path(output_dir).expanduser()\n",
        "    video_gen_root = video_dir.parent / f\"videos_generated_real2_{weight_A}\"\n",
        "    video_gen_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    vids = list(video_dir.glob(\"*.mp4\"))\n",
        "    pairs = list(combinations(vids, 2))\n",
        "    selection = random.sample(pairs, min(num_pairs, len(pairs)))\n",
        "\n",
        "    for v1_path, v2_path in selection:\n",
        "        v1, v2 = v1_path.name, v2_path.name\n",
        "        pair_name = v1_path.stem + \"_\" + v2_path.stem\n",
        "        pair_folder = out_root / pair_name\n",
        "        pair_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        shutil.copy(v1_path, pair_folder / v1)\n",
        "        shutil.copy(v2_path, pair_folder / v2)\n",
        "\n",
        "        # 1. StridedTransformer tracking\n",
        "        for vn in (v1, v2):\n",
        "            tgt = STRIDED / \"demo\" / \"video\" / vn\n",
        "            tgt.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy(pair_folder / vn, tgt)\n",
        "            subprocess.run([\"python\", \"demo/vis.py\", \"--video\", vn], cwd=STRIDED, check=True)\n",
        "\n",
        "        # 2. Convert NPZ → SMPL .npy\n",
        "        npz1 = STRIDED / \"demo\" / \"output\" / v1_path.stem / \"output_3D\" / \"output_keypoints_3d.npz\"\n",
        "        npz2 = STRIDED / \"demo\" / \"output\" / v2_path.stem / \"output_3D\" / \"output_keypoints_3d.npz\"\n",
        "        out1 = pair_folder / \"output_keypoints_3d_real1.npy\"\n",
        "        out2 = pair_folder / \"output_keypoints_3d_real2.npy\"\n",
        "\n",
        "        p1 = map_h36m_to_smpl(str(npz1)); np.save(out1, p1)\n",
        "        p2 = map_h36m_to_smpl(str(npz2)); np.save(out2, p2)\n",
        "\n",
        "        if p1.shape[0] < p2.shape[0]:\n",
        "            p1 = upsample_pose_data(str(out1), p2.shape[0]); np.save(out1, p1)\n",
        "        else:\n",
        "            p2 = upsample_pose_data(str(out2), p1.shape[0]); np.save(out2, p2)\n",
        "\n",
        "        # 3. Generate interpolated mixes\n",
        "        var_folder = pair_folder / \"all_variations\"\n",
        "        var_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for wA in [round(x, 1) for x in np.linspace(0.1, 0.9, 9)]:\n",
        "            wB = round(1 - wA, 1)\n",
        "            Popt = compute_P_opt(str(out1), str(out2), alpha=0.5, w_A=wA, w_B=wB)\n",
        "            np.save(var_folder / f\"euclidean_distances_wA{wA}_wB{wB}.npy\", Popt)\n",
        "\n",
        "        # 4. Pick selected mix and run joints2smpl\n",
        "        target_npy = var_folder / f\"euclidean_distances_wA{weight_A}_wB{round(1 - weight_A, 1)}.npy\"\n",
        "        if not target_npy.exists():\n",
        "            raise FileNotFoundError(f\"Missing variation: {target_npy}\")\n",
        "\n",
        "        dest_npy = JOINTS2SMPL / \"demo\" / \"demo_data\" / (pair_name + \"_\" + target_npy.name)\n",
        "        dest_npy.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy(target_npy, dest_npy)\n",
        "\n",
        "        subprocess.run([\n",
        "            \"python\", \"fit_seq.py\",\n",
        "            \"--files\", dest_npy.name,\n",
        "            \"--num_smplify_iters\", \"1\"\n",
        "        ], cwd=JOINTS2SMPL, check=True)\n",
        "\n",
        "        ply_src = JOINTS2SMPL / \"demo\" / \"demo_results\" / dest_npy.stem\n",
        "        if not ply_src.exists():\n",
        "            raise FileNotFoundError(f\"joints2smpl output not found: {ply_src}\")\n",
        "\n",
        "        # 5. Render PLY → PNG\n",
        "        png_folder = ANIM_REND / f\"{pair_name}_{target_npy.stem}\"\n",
        "        render_ply_sequence(ply_src, png_folder)\n",
        "\n",
        "        # 6. Assemble PNGs into MP4 using ffmpeg\n",
        "        out_mp4 = video_gen_root / f\"{pair_name}.mp4\"\n",
        "        subprocess.run([\n",
        "            \"ffmpeg\", \"-y\",\n",
        "            \"-framerate\", str(27),\n",
        "            \"-i\", str(png_folder / \"frame_%04d.png\"),\n",
        "            \"-c:v\", \"libx264\",\n",
        "            \"-pix_fmt\", \"yuv420p\",\n",
        "            str(out_mp4)\n",
        "        ], check=True)\n",
        "\n",
        "        print(\"✅ Generated:\", out_mp4)\n"
      ],
      "metadata": {
        "id": "EpuhtZenU-93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "both_real_main(\n",
        "    weight_A=0.2,\n",
        "    input_dir=\"~/autosynthda/indiv/components/dataset/specific_data\",\n",
        "    output_dir=\"~/autosynthda/indiv/components/dataset/data_manipulation\",\n",
        "    num_pairs=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "tFEmo9DJVAlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u13y73EYWC2A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}